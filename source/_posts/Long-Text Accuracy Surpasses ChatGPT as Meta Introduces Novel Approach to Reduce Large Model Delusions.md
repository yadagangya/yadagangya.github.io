---
title: Long-Text Accuracy Surpasses ChatGPT as Meta Introduces Novel Approach to Reduce Large Model Delusions
date: 2023-08-28 20:26:26
categories:
  - Internet
  - Long-Text 
tags:
  - Internet Summary 
  - Internet Briefing
  - ChatGPT
description: Long-Text Accuracy Surpasses ChatGPT as Meta Introduces Novel Approach to Reduce Large Model Delusions
cover: https://cdn.jsdelivr.net/gh/1oscar/image_house@main/2023-09-27_001229.png
---




Meta, the parent company of Facebook, has unveiled a groundbreaking method to address issues related to large language models. The company's research has resulted in improved accuracy for long-text comprehension, surpassing that of ChatGPT, OpenAI's well-known language model.

One of the major challenges with large language models like ChatGPT is their tendency to generate incorrect or nonsensical responses, commonly referred to as "hallucinations" or "delusions." These delusions occur when the model generates text that seems plausible but is factually incorrect or misleading.

Meta's new approach focuses on reducing these delusions, particularly in scenarios where long text passages are involved. The method aims to improve the model's understanding of context and reduce the likelihood of generating inaccurate information.

While Meta's specific methodology has not been detailed in the provided information, it is clear that their research has led to significant advancements in long-text comprehension accuracy. This achievement is particularly noteworthy as it outperforms ChatGPT, which is known for its language capabilities.

Reducing delusions in large language models is a critical step toward making these models more reliable and trustworthy for various applications, including natural language understanding, content generation, and chatbots. It helps ensure that the information generated by such models is not only coherent but also factually accurate.

As artificial intelligence and large language models continue to play an increasingly prominent role in various industries, advancements like Meta's new approach are essential for improving the quality of AI-generated content and maintaining the trust of users and stakeholders.



Meta AI Lab Introduces a Novel Approach to Reduce Delusions in Large Models

Meta AI Lab has proposed a "divide and conquer" solution to tackle the problem of delusions in large language models. With this approach, the accuracy of information generated by the Llama-65B model has doubled and even surpassed that of ChatGPT.

Delusions in large language models refer to the generation of text that appears plausible but is factually incorrect or misleading. Meta's new "Validation Chain" (CoVe) is a chain-like method similar to the "Chain of Thought" (CoT), with a focus on ensuring factual accuracy. While the "step-by-step" Chain of Thought emphasizes logical reasoning, the Validation Chain prioritizes factual information.

The Validation Chain works by breaking down a lengthy text into smaller segments and generating validation questions based on the generated response. The model then answers these questions and adjusts the initial response accordingly, resulting in a final answer.

Four specific ways to generate and validate questions are proposed:
1. Joint: Generating questions and answers in the same prompt.
2. 2-Step: Generating questions first, then starting a new conversation to answer them.
3. Factored: Similar to 2-Step but starting separate conversations for each question.
4. Factor+Revise: Adds consistency checks to focus on inconsistencies between responses.

Breaking down questions into smaller components makes them easier to answer, and it encourages the model to reconsider its responses, leading to improved accuracy.

Meta's research showed that applying the Validation Chain to the Llama-65B model significantly improved accuracy in tasks such as information listing and closed-domain question answering. The Validation Chain approach demonstrated substantial accuracy gains compared to models without this validation mechanism and even outperformed ChatGPT in some cases.

This innovative approach to reducing delusions in large language models is a significant step toward making these models more reliable and trustworthy in various applications. 

The research paper detailing this approach can be found at the following link: https://arxiv.org/abs/2309.11495

