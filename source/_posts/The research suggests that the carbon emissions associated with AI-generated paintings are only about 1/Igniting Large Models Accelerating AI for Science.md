---
title: Igniting Large Models Accelerating AI for Science
date: 2023-09-07 19:26:26
categories:
  - Internet
  - Large Models
tags:
  - Internet Summary 
  - Internet Briefing
  - Large Models 
description: Igniting Large Models Accelerating AI for Science
cover: https://cdn.jsdelivr.net/gh/1oscar/image_house@main/6503c40ecd99f.png
---


In the production process, 95% is a critical threshold.

As a benchmark for human performance, human accuracy ranges from 92% to 98%. Therefore, the industry adopts the median as the standard for machine tolerance. For production processes where the accuracy falls below 95%, there is little difference between accuracy rates of 80% and 90%. 

In recent years, AI technologies, represented by computer vision and speech recognition, have achieved significant success. However, limitations such as poor model interpretability and limited generalizability have hindered the widespread adoption of AI on a large scale.

The emergence of large models has changed the game by enabling continuous learning through interaction with humans, thereby enhancing their problem-solving capabilities. Industry-specific knowledge plays a crucial role in this process and has brought transformative effects to fields such as medicine, finance, security, and law.

On September 7th, at the 2023 Tencent Global Digital Ecosystem Conference - Techo Tencent Scientists Session, in collaboration with the CSIG Frontiers Exploration Club and the New Horizon Science Foundation, Tencent invited scientists from various labs and winners of the "Science Exploration Award" to focus on the frontiers of science exploration and technological applications. They shared their latest achievements in a dialogue format.

The exploration and implementation of large model technology are still in their early stages, and there is industry consensus that integrating large models into various fields will not only boost productivity but also disrupt existing production chains. It will reshape the logic from the ground up, gradually influencing various aspects, including technical research, product development, and service consumption.

Several researchers have noted in discussions with Leifeng.com (WeChat: Leifeng.com) that AI technology is being used in research and innovation in life sciences, pharmaceuticals, and more. Many are beginning to realize that large models provide a convenient tool for discovering new scientific laws and advancing AI for Science. Some predict that within the next decade, the paradigm of science will be redefined by generative AI.

Those close to scientific research understand the frontiers and disruptions behind complex scientific problems, while developers close to the industry are more aware of the challenges and opportunities of applying AI technology. What significance does the emergence of large models hold for AI for Science, and what impact will it have on its development?

With great power comes great responsibility.

"Knowledge-enhanced" industry-specific large models have become a consensus and represent a paradigm closer to human intelligence, unleashing the productivity of AI. By injecting domain knowledge into models, they improve their memory and reasoning abilities, effectively bridging the cognitive gap between basic models and specific scenarios.

However, in practice, practitioners often find things are not so simple:

A medical AI service provider using large models on the B-side told Leifeng.com that in the medical field, large models can be divided into three stages: pre-diagnosis, diagnosis, and post-diagnosis. Different training requirements are needed to address issues that may arise in each stage. For example, in pre-diagnosis, doctors used to spend a long time and a lot of effort understanding a patient's relevant information and problems before making an assessment. With large models, this part of the work can be completed using GPT, which mimics the doctor's habits and gathers pathological information from the patient by inputting medical data and their own knowledge system. However, a significant challenge is the high demand for deep semantic understanding in the medical environment. Patients rarely use specialized medical terminology when communicating with doctors. When this task is delegated to the model, can it align the patient's description with the corresponding pathological issues and make correct judgments? This is a significant challenge in building medical large models.

Medicine is highly complex, and the integration of AI technologies like large models presents a challenge for how they can be combined with the medical field.

At the Techo Tencent Scientists Session, Wang Guangyu, a specially appointed researcher at the School of Information and Communication Engineering at Beijing University of Posts and Telecommunications and winner of the 2022 "Science Exploration Award" in the field of information electronics, along with Zheng Yefeng, Tencent's outstanding scientist and head of Tencent Tianyan Laboratory, discussed the similarities and differences in technical approaches to epidemic research, monitoring, and control, as well as the landing of large models and multimodal technologies in the medical field from both academic and industrial perspectives.

Large models ignite AI for Science.

A conversation between Zheng Yefeng and Wang Guangyu

To address the "medical expertise" and trust issues with medical large models, Tencent has incorporated the medical knowledge accumulated by the Tianyan Laboratory in the medical field for many years into its medical large models. This includes structured data covering 2.85 million medical entities and 12.5 million medical relationships, which can cover approximately 98% of medical knowledge.

Zheng Yefeng pointed out that by giving professional knowledge to the model and allowing the model to refer to this knowledge during reasoning, it is possible to automatically extract relevant diseases and drugs from the patient's questions using natural language understanding technology. This information can be provided to the model from the database, enabling the model to provide more accurate answers.

Creating high-quality, specialized medical large models is also essential for improving the accuracy of scientific protests. Previously, Wang Guangyu and his team found that by using pre-trained large models, they could construct a general framework for protein-protein interactions. This framework could effectively calculate the affinity of viral proteins to the human body, allowing for better predictions of which potential mutation sites in the virus would increase its infectivity.

As large models delve deeper into specific scenarios, applications, and specific problems, their influence continues to expand, and the boundaries of their practice and implementation are further widened.

Jun Zhu, a professor in the Department of Computer Science and Technology at Tsinghua University and winner of the 2020 "Science Exploration Award" in the field of information electronics, and Yang Yu, Tencent's outstanding scientist and head of Tencent Xuanwu Laboratory, both focus on cutting-edge research in AI security. They discussed trends and challenges in network security development under the emerging technology wave.

Large models ignite AI for Science.

A conversation between Yang Yu and Jun Zhu

Network security threats at the current stage have become globalized, with attackers active every minute around the world. Yang Yu pointed out that with the support of large model technology, security personnel can effectively address the challenge of learning and training with large amounts of relevant data, which was previously required for tasks. Only minor adjustments are needed to execute instructions. By using external tools and analyzing the processing results, it can be determined whether other tools are needed to complete the task requirements.

This means that the greater the capabilities of large models, the more areas they can impact, and the greater the responsibility they bear.

Jun Zhu also stated that after AI enhances the ability to make complex reasoning decisions, it can improve its own capabilities through interaction and trial and error with minimal data labeling. This can help enhance and improve network security, bringing about significant changes to the entire security industry.

It can be seen that with generative AI-based on versatile large models as the foundation and combining them with industry-specific large models, Tencent is releasing the service capabilities of large models deeply into various industries. This is also the clearest path for the implementation of large models.

New Science, New Paradigm

In 2018, the concept of AI for Science was proposed as a tool to assist scientists in solving the many challenges they face under the current research paradigm.

One of the most representative works is AlphaFold2, which was introduced in 2021. Within just a week of its open-source release


