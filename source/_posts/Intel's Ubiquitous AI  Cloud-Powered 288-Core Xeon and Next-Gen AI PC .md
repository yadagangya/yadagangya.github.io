---
title: Intel's Ubiquitous AI  Cloud-Powered 288-Core Xeon and Next-Gen AI PC 
date: 2023-09-11 21:26:26
categories:
  - Internet
  - Intel
tags:
  - Internet Summary 
  - Internet Briefing
  - Intel
description: Intel's Ubiquitous AI  Cloud-Powered 288-Core Xeon and Next-Gen AI PC 
cover: https://cdn.jsdelivr.net/gh/1oscar/image_house@main/650a5db408829.jpg
---




Intel, a leading technology company, continues to advance its AI capabilities in various domains. Here are two significant developments:

1. **Cloud Power with 288-Core Xeon:**
   Intel has unveiled a powerful AI solution in the cloud with its 288-core Xeon processor. This processor is designed to deliver exceptional performance for AI workloads in data centers and cloud computing environments. With 288 cores, it can handle complex AI computations at scale, making it ideal for tasks like machine learning, data analytics, and deep learning. Intel's commitment to AI in the cloud underscores its dedication to pushing the boundaries of AI processing capabilities.

2. **Next-Gen AI PC at the Edge:**
   Intel is also making strides in edge computing with its Next-Generation AI PC. This represents a significant leap in AI capabilities at the edge, meaning AI processing can occur directly on devices like personal computers (PCs). This technology brings AI-powered features and intelligence to consumer devices, enabling more responsive and context-aware applications. Intel's efforts in AI at the edge mark a new era in computing where local devices can leverage advanced AI for a wide range of applications, from natural language processing to computer vision.

These developments illustrate Intel's commitment to AI across the spectrum, from powerful cloud-based solutions to cutting-edge AI capabilities on personal devices, ushering in a new era of AI ubiquity.



Intel's Ubiquitous AI: Cloud-Powered 288-Core Xeon and Next-Gen AI PC

At the 2023 Intel On Technology Innovation Conference, the stage was set for ubiquitous AI, with various partners showcasing AI innovations. Intel's CEO, Pat Gelsinger, also unveiled crucial developments, with a significant date on the horizon: December 14, 2023, when Intel plans to officially launch the fifth-generation 288-core Xeon processor.

On the same day, Intel will release its first integrated Neural Processing Unit (NPU) for Core Ultra processors. These processors, manufactured using the Intel 4 process, signify a new era for AI-powered PCs.

Behind the scenes of Intel's On Technology Innovation Conference, there's a "core economy" driving the ubiquity of AI. Gelsinger shared, "Today, chips drive an industry worth $5.74 trillion and power approximately $8 trillion of the tech economy globally."

How is Intel pushing forward the ubiquity of AI with increased computing power, AI-powered PCs, developer-friendly platforms, and advancements in processes, packaging, and multi-core solutions?

**First Glimpse at the AI Chip Roadmap: 288-Core Xeon Coming Next Year**

The roadmap is crucial for Intel, ensuring timely product deliveries as per the schedule instills confidence in customers and developers alike, while also aligning with AI strategies. Gelsinger outlined Intel's ambitious plans for expanding AI technologies in the coming year.

Based on the first-ever AI chip roadmap revealed by Gelsinger, Intel plans to release Gaudi 3 in 2024, utilizing the 5nm process, followed by the next-generation AI chip, codenamed Falcon Shores.

Gaudi 2, already launched, has performed impressively in recent MLPerf AI inference performance tests, surpassing industry benchmarks set by NVIDIA A100 in some cases. Notably, Stability AI is a major customer utilizing Gaudi 2 in a large-scale AI supercomputer.

Gaudi 3 is set to deliver substantial upgrades, with double the computing power of Gaudi 2, 1.5 times the network bandwidth, and increased HBM capacity.

Intel's fifth-generation Xeon processor, set to launch on December 14, 2023, will provide improved performance and storage speed for global data centers while maintaining the same power consumption.

The energy-efficient core processor, Sierra Forest, is expected to hit the market in the first half of 2024. With 288 cores, it's projected to increase rack density by 2.5 times and deliver 2.4 times the performance per watt compared to the fourth-generation Xeon.

Following Sierra Forest, the high-performance core processor, Granite Rapids, is anticipated to enhance AI performance by 2 to 3 times compared to its predecessor. The fourth-generation Xeon processors have already significantly accelerated large model processing for Alibaba Cloud.

Looking ahead, Intel is set to launch its next-generation power-efficient core processor, codenamed Clearwater Forest, in 2025, utilizing the Intel 18A process node.

**First Integrated NPU for Core Ushers in a New Era of AI PCs**

Gelsinger's keynote repeatedly emphasized the significance of AI PCs in driving AI ubiquity. He believes that "AI, in close collaboration between the cloud and PCs, will fundamentally change, reshape, and reconstruct the PC experience, unlocking people's productivity and creativity. We are moving towards a new era of AI PCs."

A pivotal product in this new AI PC era is the Core Ultra processor, codenamed Meteor Lake, which will also be unveiled on December 14. It's a game-changer in Intel's client processor roadmap, offering several highlights. It utilizes the Intel 4 process node, significantly improving performance while reducing power consumption. Notably, it's Intel's first client product with an integrated Neural Processing Unit (NPU) and utilizes Foveros packaging technology.

Additionally, the Core Ultra processor integrates Intel's powerful Xe graphics, delivering performance on par with dedicated graphics cards.

These performance enhancements open up new possibilities for edge applications. With a PC powered by the Core Ultra processor, users can generate songs in the style of Taylor Swift using generative AI models. They can extract audio and video content with AI, run large language models locally using Intel OpenVINO even without an internet connection, and engage with AI chatbots for real-time Q&A.

Efficiently recording and translating meeting content during online video conferences and extracting key meeting highlights upon returning to the conference are also made possible with AI.

Acer is set to be among the first to launch laptops featuring the Core Ultra processor. Acer's COO, Jerry Kao, stated, "We collaborated with the Intel team to develop an Acer AI library using the OpenVINO toolkit, fully leveraging the Intel Core Ultra platform. Together, we have developed an AI library that will eventually bring this product to users."

Intel's AI inference and deployment toolkit, OpenVINO, is a crucial tool for developers, enabling AI ubiquity in both the cloud and on the edge.

**Developer-Driven Tools for the Core Economy**

Software serves as both a developer's tool and a weapon to drive the core economy. Gelsinger believes that the future of AI must contribute to improved accessibility, scalability, visibility, transparency, and trust across the entire ecosystem. This entails having highly usable software and platforms from the cloud to the endpoint.

High Koo, President of Fit:Match, mentioned OpenVINO as a vital tool in their development process. With the latest release, OpenVINO Toolkit 2023.1 includes optimized pre-trained models for cross-operating systems and various cloud solutions, including generative AI model Llama 2.

Developers can leverage OpenVINO to create products like Fit:Match, which evaluates athlete performance or helps consumers find better-fitting clothes.

At the 2023 Intel On Technology Innovation Conference, Gelsinger announced the comprehensive launch of the Intel Developer Cloud platform.

One significant advantage of the Developer Cloud is that developers can use unreleased Intel chips for product development, shortening time to market by approximately a year. This includes products like the fifth-generation Intel Xeon Scalable processor and Intel Data Center GPU Max series 1100 and 1550, which are not yet in mass production.

Built upon the oneAPI framework, the Intel Developer Cloud platform allows developers to choose hardware, break free from proprietary programming models, and support accelerated computing, code reusability, and portability.

Developers using the Intel Developer Cloud can build, test, and optimize AI and scientific computing applications, run AI training, model optimization, and inference workloads from small to large scale for high performance and efficiency.

In addition to OpenVINO and the Intel Developer Cloud, Gelsinger also revealed the Strata project and an edge-native software platform slated for launch in 2024.

This forward-looking software platform recognizes that most AI development and applications currently rely on the cloud. As AI technology matures, the edge and endpoints will carry more AI computing and applications, making it crucial to achieve AI ubiquity.

The Strata project and the edge-native software platform aim to provide the infrastructure needed to enable developers to build, deploy, run, manage, connect, and secure distributed edge infrastructure and applications.

**Advancements in Advanced Packaging and Multi-Chip Solutions Keep Moore's Law Alive**

Whether it's improving chip performance or enhancing the software development platform, the foundation lies in processes and packaging. Gelsinger stated that Intel's "four years, five process nodes" plan is


